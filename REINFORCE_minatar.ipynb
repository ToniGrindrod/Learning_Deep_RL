{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DAtUO4yiu-Dm",
        "outputId": "3fd54e16-8ef0-43a5-fbd4-97090273c76f"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[neptune] [warning] NeptuneDeprecationWarning: The 'neptune-client' package has been deprecated and will be removed in the future. Install the 'neptune' package instead. For more, see https://docs.neptune.ai/setup/upgrading/\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import torch\n",
        "import warnings\n",
        "import numpy as np\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "import gymnasium as gym\n",
        "import neptune\n",
        "from matplotlib import pyplot as plt\n",
        "from minatar import Environment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "WBMRNZF44KCg",
        "outputId": "ca09fad6-46ce-40c0-c153-94015a35289c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.5.1+cu124)\n",
            "Collecting torch\n",
            "  Downloading torch-2.6.0-cp311-cp311-manylinux1_x86_64.whl.metadata (28 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch) (3.17.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.5)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2024.10.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparselt-cu12==0.6.2 (from torch)\n",
            "  Downloading nvidia_cusparselt_cu12-0.6.2-py3-none-manylinux2014_x86_64.whl.metadata (6.8 kB)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting triton==3.2.0 (from torch)\n",
            "  Downloading triton-3.2.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.4 kB)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Downloading torch-2.6.0-cp311-cp311-manylinux1_x86_64.whl (766.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m766.7/766.7 MB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m99.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m88.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m59.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m13.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparselt_cu12-0.6.2-py3-none-manylinux2014_x86_64.whl (150.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m150.1/150.1 MB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m93.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading triton-3.2.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (253.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m253.2/253.2 MB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: triton, nvidia-cusparselt-cu12, nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, torch\n",
            "  Attempting uninstall: triton\n",
            "    Found existing installation: triton 3.1.0\n",
            "    Uninstalling triton-3.1.0:\n",
            "      Successfully uninstalled triton-3.1.0\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 2.5.1+cu124\n",
            "    Uninstalling torch-2.5.1+cu124:\n",
            "      Successfully uninstalled torch-2.5.1+cu124\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torchvision 0.20.1+cu124 requires torch==2.5.1, but you have torch 2.6.0 which is incompatible.\n",
            "fastai 2.7.18 requires torch<2.6,>=1.10, but you have torch 2.6.0 which is incompatible.\n",
            "torchaudio 2.5.1+cu124 requires torch==2.5.1, but you have torch 2.6.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-cusparselt-cu12-0.6.2 nvidia-nvjitlink-cu12-12.4.127 torch-2.6.0 triton-3.2.0\n"
          ]
        },
        {
          "data": {
            "application/vnd.colab-display-data+json": {
              "id": "b1085edd704d4c57bfbf583b15e6780c",
              "pip_warning": {
                "packages": [
                  "torchgen"
                ]
              }
            }
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: triton in /usr/local/lib/python3.11/dist-packages (3.2.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install torch --upgrade\n",
        "!pip install triton --upgrade\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "6Pyx3IlovAVh",
        "outputId": "4d1a228c-389e-4537-a89b-f3acababe60d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting neptune-client\n",
            "  Downloading neptune_client-1.13.0-py3-none-any.whl.metadata (16 kB)\n",
            "Requirement already satisfied: GitPython>=2.0.8 in /usr/local/lib/python3.11/dist-packages (from neptune-client) (3.1.44)\n",
            "Requirement already satisfied: Pillow>=1.1.6 in /usr/local/lib/python3.11/dist-packages (from neptune-client) (11.1.0)\n",
            "Requirement already satisfied: PyJWT in /usr/local/lib/python3.11/dist-packages (from neptune-client) (2.10.1)\n",
            "Collecting boto3>=1.28.0 (from neptune-client)\n",
            "  Downloading boto3-1.36.23-py3-none-any.whl.metadata (6.7 kB)\n",
            "Collecting bravado<12.0.0,>=11.0.0 (from neptune-client)\n",
            "  Downloading bravado-11.1.0-py2.py3-none-any.whl.metadata (6.0 kB)\n",
            "Requirement already satisfied: click>=7.0 in /usr/local/lib/python3.11/dist-packages (from neptune-client) (8.1.8)\n",
            "Requirement already satisfied: future>=0.17.1 in /usr/local/lib/python3.11/dist-packages (from neptune-client) (1.0.0)\n",
            "Requirement already satisfied: oauthlib>=2.1.0 in /usr/local/lib/python3.11/dist-packages (from neptune-client) (3.2.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from neptune-client) (24.2)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from neptune-client) (2.2.2)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from neptune-client) (5.9.5)\n",
            "Requirement already satisfied: requests>=2.20.0 in /usr/local/lib/python3.11/dist-packages (from neptune-client) (2.32.3)\n",
            "Requirement already satisfied: requests-oauthlib>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from neptune-client) (2.0.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.11/dist-packages (from neptune-client) (1.17.0)\n",
            "Collecting swagger-spec-validator>=2.7.4 (from neptune-client)\n",
            "  Downloading swagger_spec_validator-3.0.4-py2.py3-none-any.whl.metadata (2.5 kB)\n",
            "Requirement already satisfied: typing-extensions>=3.10.0 in /usr/local/lib/python3.11/dist-packages (from neptune-client) (4.12.2)\n",
            "Requirement already satisfied: urllib3 in /usr/local/lib/python3.11/dist-packages (from neptune-client) (2.3.0)\n",
            "Requirement already satisfied: websocket-client!=1.0.0,>=0.35.0 in /usr/local/lib/python3.11/dist-packages (from neptune-client) (1.8.0)\n",
            "Collecting botocore<1.37.0,>=1.36.23 (from boto3>=1.28.0->neptune-client)\n",
            "  Downloading botocore-1.36.23-py3-none-any.whl.metadata (5.7 kB)\n",
            "Collecting jmespath<2.0.0,>=0.7.1 (from boto3>=1.28.0->neptune-client)\n",
            "  Downloading jmespath-1.0.1-py3-none-any.whl.metadata (7.6 kB)\n",
            "Collecting s3transfer<0.12.0,>=0.11.0 (from boto3>=1.28.0->neptune-client)\n",
            "  Downloading s3transfer-0.11.2-py3-none-any.whl.metadata (1.7 kB)\n",
            "Collecting bravado-core>=5.16.1 (from bravado<12.0.0,>=11.0.0->neptune-client)\n",
            "  Downloading bravado-core-6.1.1.tar.gz (63 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.9/63.9 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting monotonic (from bravado<12.0.0,>=11.0.0->neptune-client)\n",
            "  Downloading monotonic-1.6-py2.py3-none-any.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: msgpack in /usr/local/lib/python3.11/dist-packages (from bravado<12.0.0,>=11.0.0->neptune-client) (1.1.0)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.11/dist-packages (from bravado<12.0.0,>=11.0.0->neptune-client) (2.8.2)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.11/dist-packages (from bravado<12.0.0,>=11.0.0->neptune-client) (6.0.2)\n",
            "Collecting simplejson (from bravado<12.0.0,>=11.0.0->neptune-client)\n",
            "  Downloading simplejson-3.20.1-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.2 kB)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.11/dist-packages (from GitPython>=2.0.8->neptune-client) (4.0.12)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.20.0->neptune-client) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.20.0->neptune-client) (3.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.20.0->neptune-client) (2025.1.31)\n",
            "Requirement already satisfied: jsonschema in /usr/local/lib/python3.11/dist-packages (from swagger-spec-validator>=2.7.4->neptune-client) (4.23.0)\n",
            "Requirement already satisfied: importlib-resources>=1.3 in /usr/local/lib/python3.11/dist-packages (from swagger-spec-validator>=2.7.4->neptune-client) (6.5.2)\n",
            "Requirement already satisfied: numpy>=1.23.2 in /usr/local/lib/python3.11/dist-packages (from pandas->neptune-client) (1.26.4)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->neptune-client) (2025.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->neptune-client) (2025.1)\n",
            "Collecting jsonref (from bravado-core>=5.16.1->bravado<12.0.0,>=11.0.0->neptune-client)\n",
            "  Downloading jsonref-1.1.0-py3-none-any.whl.metadata (2.7 kB)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.11/dist-packages (from gitdb<5,>=4.0.1->GitPython>=2.0.8->neptune-client) (5.0.2)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.11/dist-packages (from jsonschema->swagger-spec-validator>=2.7.4->neptune-client) (25.1.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.11/dist-packages (from jsonschema->swagger-spec-validator>=2.7.4->neptune-client) (2024.10.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.11/dist-packages (from jsonschema->swagger-spec-validator>=2.7.4->neptune-client) (0.36.2)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from jsonschema->swagger-spec-validator>=2.7.4->neptune-client) (0.22.3)\n",
            "Collecting fqdn (from jsonschema[format-nongpl]>=2.5.1->bravado-core>=5.16.1->bravado<12.0.0,>=11.0.0->neptune-client)\n",
            "  Downloading fqdn-1.5.1-py3-none-any.whl.metadata (1.4 kB)\n",
            "Collecting isoduration (from jsonschema[format-nongpl]>=2.5.1->bravado-core>=5.16.1->bravado<12.0.0,>=11.0.0->neptune-client)\n",
            "  Downloading isoduration-20.11.0-py3-none-any.whl.metadata (5.7 kB)\n",
            "Requirement already satisfied: jsonpointer>1.13 in /usr/local/lib/python3.11/dist-packages (from jsonschema[format-nongpl]>=2.5.1->bravado-core>=5.16.1->bravado<12.0.0,>=11.0.0->neptune-client) (3.0.0)\n",
            "Collecting rfc3339-validator (from jsonschema[format-nongpl]>=2.5.1->bravado-core>=5.16.1->bravado<12.0.0,>=11.0.0->neptune-client)\n",
            "  Downloading rfc3339_validator-0.1.4-py2.py3-none-any.whl.metadata (1.5 kB)\n",
            "Collecting rfc3986-validator>0.1.0 (from jsonschema[format-nongpl]>=2.5.1->bravado-core>=5.16.1->bravado<12.0.0,>=11.0.0->neptune-client)\n",
            "  Downloading rfc3986_validator-0.1.1-py2.py3-none-any.whl.metadata (1.7 kB)\n",
            "Collecting uri-template (from jsonschema[format-nongpl]>=2.5.1->bravado-core>=5.16.1->bravado<12.0.0,>=11.0.0->neptune-client)\n",
            "  Downloading uri_template-1.3.0-py3-none-any.whl.metadata (8.8 kB)\n",
            "Requirement already satisfied: webcolors>=24.6.0 in /usr/local/lib/python3.11/dist-packages (from jsonschema[format-nongpl]>=2.5.1->bravado-core>=5.16.1->bravado<12.0.0,>=11.0.0->neptune-client) (24.11.1)\n",
            "Collecting arrow>=0.15.0 (from isoduration->jsonschema[format-nongpl]>=2.5.1->bravado-core>=5.16.1->bravado<12.0.0,>=11.0.0->neptune-client)\n",
            "  Downloading arrow-1.3.0-py3-none-any.whl.metadata (7.5 kB)\n",
            "Collecting types-python-dateutil>=2.8.10 (from arrow>=0.15.0->isoduration->jsonschema[format-nongpl]>=2.5.1->bravado-core>=5.16.1->bravado<12.0.0,>=11.0.0->neptune-client)\n",
            "  Downloading types_python_dateutil-2.9.0.20241206-py3-none-any.whl.metadata (2.1 kB)\n",
            "Downloading neptune_client-1.13.0-py3-none-any.whl (502 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m502.7/502.7 kB\u001b[0m \u001b[31m20.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading boto3-1.36.23-py3-none-any.whl (139 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m139.2/139.2 kB\u001b[0m \u001b[31m16.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading bravado-11.1.0-py2.py3-none-any.whl (37 kB)\n",
            "Downloading swagger_spec_validator-3.0.4-py2.py3-none-any.whl (28 kB)\n",
            "Downloading botocore-1.36.23-py3-none-any.whl (13.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.4/13.4 MB\u001b[0m \u001b[31m103.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jmespath-1.0.1-py3-none-any.whl (20 kB)\n",
            "Downloading s3transfer-0.11.2-py3-none-any.whl (84 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.2/84.2 kB\u001b[0m \u001b[31m8.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading monotonic-1.6-py2.py3-none-any.whl (8.2 kB)\n",
            "Downloading simplejson-3.20.1-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (144 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m144.8/144.8 kB\u001b[0m \u001b[31m17.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jsonref-1.1.0-py3-none-any.whl (9.4 kB)\n",
            "Downloading rfc3986_validator-0.1.1-py2.py3-none-any.whl (4.2 kB)\n",
            "Downloading fqdn-1.5.1-py3-none-any.whl (9.1 kB)\n",
            "Downloading isoduration-20.11.0-py3-none-any.whl (11 kB)\n",
            "Downloading rfc3339_validator-0.1.4-py2.py3-none-any.whl (3.5 kB)\n",
            "Downloading uri_template-1.3.0-py3-none-any.whl (11 kB)\n",
            "Downloading arrow-1.3.0-py3-none-any.whl (66 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m66.4/66.4 kB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading types_python_dateutil-2.9.0.20241206-py3-none-any.whl (14 kB)\n",
            "Building wheels for collected packages: bravado-core\n",
            "  Building wheel for bravado-core (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for bravado-core: filename=bravado_core-6.1.1-py2.py3-none-any.whl size=67675 sha256=67b750f243df37de0e22aab1f9cdab3cdc75d1f0d6a8076e3f7de42639482777\n",
            "  Stored in directory: /root/.cache/pip/wheels/cf/d7/1c/1d707a21e0a0323bdbfbb2f6de125ae6bb70d62aa2838df321\n",
            "Successfully built bravado-core\n",
            "Installing collected packages: monotonic, uri-template, types-python-dateutil, simplejson, rfc3986-validator, rfc3339-validator, jsonref, jmespath, fqdn, botocore, arrow, s3transfer, isoduration, swagger-spec-validator, boto3, bravado-core, bravado, neptune-client\n",
            "Successfully installed arrow-1.3.0 boto3-1.36.23 botocore-1.36.23 bravado-11.1.0 bravado-core-6.1.1 fqdn-1.5.1 isoduration-20.11.0 jmespath-1.0.1 jsonref-1.1.0 monotonic-1.6 neptune-client-1.13.0 rfc3339-validator-0.1.4 rfc3986-validator-0.1.1 s3transfer-0.11.2 simplejson-3.20.1 swagger-spec-validator-3.0.4 types-python-dateutil-2.9.0.20241206 uri-template-1.3.0\n"
          ]
        }
      ],
      "source": [
        "!pip install neptune-client"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Abco6h-Wu-Dr"
      },
      "source": [
        "PyTorch device setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y9ZahonRu-Dw"
      },
      "outputs": [],
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kk1jB5YCu-Dx"
      },
      "source": [
        "Seed for reproducible results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "G9ljETE3u-Dx"
      },
      "outputs": [],
      "source": [
        "seed = 2025\n",
        "np.random.seed(seed)\n",
        "np.random.default_rng(seed)\n",
        "os.environ['PYTHONHASHSEED'] = str(seed)\n",
        "torch.manual_seed(seed)\n",
        "if torch.cuda.is_available():\n",
        "    torch.cuda.manual_seed(seed)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = False\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9ZNUEIIgu-Dy"
      },
      "outputs": [],
      "source": [
        "class PolicyNet(nn.Module):\n",
        "    def __init__(self, input_shape, output_size):\n",
        "        super(PolicyNet, self).__init__()\n",
        "        \n",
        "        c, h, w = input_shape  # Extract channels, height, width\n",
        "\n",
        "        self.conv1 = nn.Conv2d(c, 16, kernel_size=3, stride=1, padding=1)  # Conv layer\n",
        "        self.conv2 = nn.Conv2d(16, 32, kernel_size=3, stride=1, padding=1) # Another Conv layer\n",
        "        self.fc1 = nn.Linear(32 * h * w, 128)  # Fully connected layer\n",
        "        self.fc2 = nn.Linear(128, output_size) # Output layer\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Permute the input from (batch_size, height, width, channels) to (batch_size, channels, height, width)\n",
        "        #need to do this to match shape expected for torch's Conv2d\n",
        "        x = x.permute(0, 3, 1, 2)  # Reorder dimensions to match PyTorch's Conv2d format: (batch_size, c, h, w)\n",
        "\n",
        "        x = F.relu(self.conv1(x))  # First Conv layer + ReLU\n",
        "        x = F.relu(self.conv2(x))  # Second Conv layer + ReLU\n",
        "        x = torch.flatten(x, start_dim=1)  # Flatten for the FC layer\n",
        "        x = F.relu(self.fc1(x))  # First FC layer\n",
        "        x = self.fc2(x)  # Output logits (no softmax, handled by policy function)\n",
        "        return F.softmax(x, dim=1)  # Action probabilities"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HqAcRTB2u-Dz"
      },
      "outputs": [],
      "source": [
        "class ReinforceNNLearber:\n",
        "    def __init__(self, env, device, run, gamma=0.99, learning_rate=9.8e-4, num_episodes = 500):\n",
        "        self.env = env\n",
        "        self.run = run  # Store the Neptune run\n",
        "        self.gamma = gamma #discount factor\n",
        "        self.learning_rate = learning_rate\n",
        "        self.device = device\n",
        "        # Define the policy network\n",
        "\n",
        "        # Get number of actions from gym action space\n",
        "        ###THIS CHANGED FOR MINATAR\n",
        "        n_actions = self.env.num_actions()\n",
        "        # Reset and get the number of state observations\n",
        "        ###THIS CHANGED FOR MINATAR\n",
        "        self.env.reset()\n",
        "        state=self.env.state()\n",
        "\n",
        "\n",
        "        ###THIS CHANGED FOR MINATAR\n",
        "        # Assuming state shape is (10, 10, c), where c is the number of channels\n",
        "\n",
        "        self.policy_net = PolicyNet(state.shape(), n_actions).to(self.device)\n",
        "        self.optimizer = optim.Adam(self.policy_net.parameters(), lr=self.learning_rate)\n",
        "        # when initialise like this, you're telling the optimizer how large each step (or update) should be in the gradient descent process. In this case, the learning rate (self.learning_rate) controls the size of the step taken during the optimization step.\n",
        "        self.num_episodes = num_episodes\n",
        "\n",
        "    def preprocess_state(self, state):\n",
        "        \"\"\"\n",
        "        Preprocesses the state by transforming it to tensor and adding a batch dimension.\n",
        "\n",
        "        Args:\n",
        "            state (numpy.ndarray): Input state from the environment.\n",
        "\n",
        "        Returns:\n",
        "            torch.Tensor: State tensor with batch dimension.\n",
        "        \"\"\"\n",
        "\n",
        "        #convert into a pytorch tensor. then unsqueeze to add dimension to the tensor at position zero - NN in pytorch expect batched inputs, first dim batch size.\n",
        "        #.to(self.device) moves the tensor to the device. Because operations on tensors in pytorch must happen on the same device.\n",
        "        normalized_state = torch.as_tensor(state, dtype=torch.float32, device=self.device)\n",
        "        normalized_state = normalized_state.unsqueeze(0)\n",
        "\n",
        "        return normalized_state\n",
        "\n",
        "\n",
        "    def compute_returns(self, rewards):\n",
        "        \"\"\"\n",
        "        Computes discounted returns.\n",
        "\n",
        "        Args:\n",
        "            rewards (list): List of rewards for each time step.\n",
        "\n",
        "        Returns:\n",
        "            numpy.ndarray: Array of discounted returns.\n",
        "\n",
        "        \"\"\"\n",
        "\n",
        "        t_steps = np.arange(len(rewards))\n",
        "        r = rewards * self.gamma ** t_steps # Compute discounted rewards for each time step\n",
        "\n",
        "        # Compute the discounted cumulative sum in reverse order and then reverse it again to restore the original order.\n",
        "        r = np.cumsum(r[::-1])[::-1] / self.gamma ** t_steps\n",
        "\n",
        "        return r\n",
        "    #What I had before was less efficient but achieved same result:\n",
        "    #returns = []\n",
        "    # cumulative_return = 0\n",
        "    # for _, _, reward, _ in reversed(episode):\n",
        "    #     cumulative_return = reward + self.gamma * cumulative_return\n",
        "    #     returns.insert(0, cumulative_return)\n",
        "\n",
        "\n",
        "    def compute_loss(self,log_probs, returns):\n",
        "        \"\"\"\n",
        "        Computes the policy gradient loss based on the formula.\n",
        "\n",
        "        Args:\n",
        "            log_probs (list): List of log probabilities of selected actions.\n",
        "            returns (numpy.ndarray): Array of discounted returns.\n",
        "\n",
        "        Returns:\n",
        "            torch.Tensor: Computed loss.\n",
        "\n",
        "        \"\"\"\n",
        "\n",
        "        policy_loss = []\n",
        "        for log_prob, returns in zip(log_probs, returns):#pairs each element of the log_prob with the CORRESPONDING element in the returns list. Outputs an iterator of tuples each containing one element from log_prob and one element from returns.\n",
        "            #zip(epilog_probsode, returns) will create tuples like this: [(log_prob1, return_1),...]\n",
        "            policy_loss.append(-log_prob * returns)\n",
        "            # Negative sign for gradient ascent\n",
        "            #since we want to maximize the expected return but most optimizers minimize a loss function, we accumulate the negative term for each time step\n",
        "            #for each time step we calculate log_prob*Gt wehich represents how much the chosen action contributed to the overall reward in terms of the log-likelihood of the action multiplied by the expected reward (how much the action contributes to the final rewards, weighted by how likely the policy was to choose that action)\n",
        "\n",
        "        return torch.stack(policy_loss).sum()\n",
        "        #we sum all the losses for the entire episode\n",
        "        #torch.stack(policy_loss) takes the list of tensors stored in policy_loss and combines them into a single tensor, stacking them along a new dimension\n",
        "        #.sum() is applied to the stacked tensor to sum the individual elements of the loss across the batch\n",
        "\n",
        "\n",
        "    def train(self):\n",
        "        self.policy_net.train()  # Ensures the network is in training mode\n",
        "        episode_rewards = []\n",
        "        # Main training loop that loops over each episode\n",
        "        for episode in range(1, self.num_episodes + 1):\n",
        "            self.env.reset()\n",
        "            # state() returns a NumPy array of shape (10, 10, c)\n",
        "            state=self.env.state()\n",
        "            \n",
        "            # Initialize empty lists to store log probabilities and rewards for the episode\n",
        "            log_probs = []\n",
        "            episode_reward = []\n",
        "\n",
        "            # Loop until the episode is done\n",
        "            while True:\n",
        "                state = self.preprocess_state(state) # Preprocesses the state to convert it to tensor\n",
        "                action_probs = self.policy_net(state) # Forward pass through policy network to get action probabilities\n",
        "                #Passes the current state through the policy network to comput the probabilities of taking each action.\n",
        "                #returns the action probabilities for the given state as predicted by the policy network. Type: pytorch tensor. Shape: (batch_size, num_actions)\n",
        "\n",
        "                # Sample an action from the action probabilities\n",
        "                dist = torch.distributions.Categorical(action_probs)\n",
        "                #creates a categorical (discrete - since discrete actions) probability distribution based on the action probabilities.\n",
        "                #The categorical distribution object provides methods to sample actions or comput the log_probabilities of actions\n",
        "                action = dist.sample()\n",
        "                #Take the action in the environment\n",
        "\n",
        "                # Compute the log probability of the sampled action\n",
        "                log_prob = dist.log_prob(action)\n",
        "                log_probs.append(log_prob)\n",
        "\n",
        "                # Take a step in the environment\n",
        "                reward, done = self.env.act(action.item())\n",
        "                next_state=self.env.state()\n",
        "                #same as before except now have .item() which extracts the scalar value from a pytorch tensor.\n",
        "                # Action is typically a PyTorch tensor representing the action selected by the policy. If action is sampled from a Categorical distribution, its type will be a 0-dimensional tensor (a scalar tensor), for example: tensor(2)\n",
        "                #.item() extracts the scalar value from the tensor and converts it into a plain python integer which is expected by gym as input to step()\n",
        "                episode_reward.append(reward)\n",
        "\n",
        "                state = next_state # Move to the next state\n",
        "\n",
        "                if done: # if the episode is done\n",
        "                    returns = self.compute_returns(episode_reward) # Compute the returns (discounted sum of rewards) for the episode\n",
        "                    loss = self.compute_loss(log_probs, returns)  # Compute the loss for the episode using the log probabilities and returns\n",
        "                    self.optimizer.zero_grad()\n",
        "                    #clears the gradients of all parameters (weights and biases) that are being optimized by the optimizer. It ensures that the gradients from the previous backward pass are reset to zero before the new backward pass. Ensures gradients are not accumulated.\n",
        "                    #In PyTorch, when you perform a forward pass through a neural network and then call .backward() to compute the gradients, the gradients of the parameters in the network are stored in the .grad attribute of each parameter.\n",
        "                    #These gradients are used for updating the parameters during the optimization step.\n",
        "                    #By default,  PyTorch accumulates gradients, meaning it adds the gradients computed during each backward pass to the existing ones. This is useful in some cases, such as when you are training with mini-batches and want to accumulate gradients across multiple steps before updating the parameters.\n",
        "                    #However, for each new training step, you typically want to reset the gradients to zero to avoid carrying over gradients from the previous batch or episode.\n",
        "\n",
        "                    loss.backward() #computes the gradients of the loss with respect to the parameters of the policy network using backpropagation.\n",
        "                    self.optimizer.step() #instance of an adam optimizer which updates the policy network's weights based on the gradients that were computed during backpropagation.\n",
        "                    #Adam optimizer automatically adjusts the learning rate for each parameter based on the gradients and their respective magnitudes.\n",
        "                    #The learning rate helps to control the step size in parameter updates, ensuring that the network learns at a reasonable pace without overshooting the optimal solution.\n",
        "\n",
        "                    episode_reward = sum(episode_reward) # Compute the total reward for the episode\n",
        "\n",
        "                    #print(f\"Episode {episode}, Ep Reward: {episode_reward}\")\n",
        "                    self.run[\"episode_rewards\"].log(episode_reward)\n",
        "                    episode_rewards.append(episode_reward)\n",
        "\n",
        "                    break # Exit the episode loop\n",
        "\n",
        "        return episode_rewards"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kzNm3ujQ26ju"
      },
      "outputs": [],
      "source": [
        "def main_Minatar(learning_rate,gamma):\n",
        "    my_api=\"eyJhcGlfYWRkcmVzcyI6Imh0dHBzOi8vYXBwLm5lcHR1bmUuYWkiLCJhcGlfdXJsIjoiaHR0cHM6Ly9hcHAubmVwdHVuZS5haSIsImFwaV9rZXkiOiJjZDg3ZjNlYi04MWI3LTQ1ODctOGIxNS1iNTY3ZjgzMGYzMzYifQ==\"\n",
        "    run = neptune.init_run(\n",
        "    project=\"EnergyGridRL/REINFORCE-Minatar\",\n",
        "    api_token=my_api\n",
        ")  # your credentials\n",
        "    # Create the environment\n",
        "    params = {\"GAMMA\":gamma,#0.99,\n",
        "               \"LR\":learning_rate,#9.8e-4\n",
        "               \"num_episodes\":10000}\n",
        "    run[\"parameters\"] = params# Use the grid size in the environment\n",
        "    env = Environment(env_name=\"breakout\")\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    print(f\"Using device: {device}\")\n",
        "    # Create the Q-LEARNING agent\n",
        "\n",
        "    agent = ReinforceNNLearber(\n",
        "               env=env,\n",
        "               device=device,\n",
        "               run=run,\n",
        "               gamma=params[\"GAMMA\"],\n",
        "               learning_rate=params[\"LR\"],\n",
        "               num_episodes = params[\"num_episodes\"])\n",
        "\n",
        "    # Train the agent\n",
        "    episode_rewards = np.array(agent.train())\n",
        "\n",
        "    # Stop the Neptune run\n",
        "    run.stop()\n",
        "\n",
        "    plt.plot(episode_rewards)\n",
        "    plt.xlabel(\"Episode\")\n",
        "    plt.ylabel(\"Total Reward\")\n",
        "    plt.title(\"Training Performance\")\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wXVpN_p280li",
        "outputId": "4d0a3a82-1fc6-4839-dbef-1ed8494c6475"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting swig\n",
            "  Downloading swig-4.3.0-py2.py3-none-manylinux_2_5_x86_64.manylinux1_x86_64.whl.metadata (3.5 kB)\n",
            "Downloading swig-4.3.0-py2.py3-none-manylinux_2_5_x86_64.manylinux1_x86_64.whl (1.9 MB)\n",
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/1.9 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.3/1.9 MB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m32.8 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m26.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: swig\n",
            "Successfully installed swig-4.3.0\n",
            "Requirement already satisfied: gymnasium[box2d] in /usr/local/lib/python3.11/dist-packages (1.0.0)\n",
            "Requirement already satisfied: numpy>=1.21.0 in /usr/local/lib/python3.11/dist-packages (from gymnasium[box2d]) (1.26.4)\n",
            "Requirement already satisfied: cloudpickle>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from gymnasium[box2d]) (3.1.1)\n",
            "Requirement already satisfied: typing-extensions>=4.3.0 in /usr/local/lib/python3.11/dist-packages (from gymnasium[box2d]) (4.12.2)\n",
            "Requirement already satisfied: farama-notifications>=0.0.1 in /usr/local/lib/python3.11/dist-packages (from gymnasium[box2d]) (0.0.4)\n",
            "Collecting box2d-py==2.3.5 (from gymnasium[box2d])\n",
            "  Downloading box2d-py-2.3.5.tar.gz (374 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m374.4/374.4 kB\u001b[0m \u001b[31m9.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: pygame>=2.1.3 in /usr/local/lib/python3.11/dist-packages (from gymnasium[box2d]) (2.6.1)\n",
            "Requirement already satisfied: swig==4.* in /usr/local/lib/python3.11/dist-packages (from gymnasium[box2d]) (4.3.0)\n",
            "Building wheels for collected packages: box2d-py\n",
            "  Building wheel for box2d-py (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for box2d-py: filename=box2d_py-2.3.5-cp311-cp311-linux_x86_64.whl size=2379490 sha256=ab0b04b4d9b0880ef44bb8b38aa72987ba59a676b25b084fa5090d361b3ccc38\n",
            "  Stored in directory: /root/.cache/pip/wheels/ab/f1/0c/d56f4a2bdd12bae0a0693ec33f2f0daadb5eb9753c78fa5308\n",
            "Successfully built box2d-py\n",
            "Installing collected packages: box2d-py\n",
            "Successfully installed box2d-py-2.3.5\n"
          ]
        }
      ],
      "source": [
        "!pip install swig\n",
        "!pip install \"gymnasium[box2d]\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NlZbfAlY8Zk-",
        "outputId": "4e244a53-26ac-4798-ff58-f7100b67a4fc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[neptune] [info   ] Neptune initialized. Open in the app: https://app.neptune.ai/EnergyGridRL/LunarREINFORCE/e/LUN2-6\n",
            "Using device: cuda\n"
          ]
        }
      ],
      "source": [
        "main_Minatar(1e-3,0.99)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
